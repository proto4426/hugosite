---
title: "MLE for Censored Data"
author: "Mark Hagemann"
date: "2016-01-03"
output: html_document
---



<p>Suppose you want to know something about a random variable that is only measurable when its value is above a certain threshold. For example, you have a dataset of the concentration of nitrate in a river (measured monthly for the last 100 months), but the analytical instrument has a detection limit below which it stops working. Such data are called <em>censored</em> in the statistical community. How can you do inference on such data? One approach might be to throw out all of the BDL (Below Detection Limit) data and do your inference on the remains of the dataset. A second approach might be to assign some arbitrary value to the BDLs, for example 1/2 the limit, and proceed using this modified dataset. Both of these approaches, particularly the omission of BDLs, are not recommended, and can severely bias your results. (See Dennis Helsel’s myriad papers/book on the subject for reasons why.)</p>
<p>A third approach, much preferred when the data can be assumed to follow a parametric distribution, is to use maximum likelihood estimation. Consider a set of observations of a random variable <span class="math inline">\(Y\)</span> with pdf <span class="math inline">\(f(y|\mathbf{\theta})\)</span> and cdf <span class="math inline">\(F(y|\mathbf{\theta})\)</span>. In the usual, non-censored case, maximum likelihood would maximize (with respect to the parameters <span class="math inline">\(\mathbf{\theta}\)</span>) the function</p>
<p><span class="math display">\[
L(\mathbf{\theta}) = \prod_{i = 1}^n f(y_i | \mathbf{\theta})
\]</span></p>
<p>A simple modification can be made for censored data of this kind. The modified likelihood function is</p>
<p><span class="math display">\[
L(\theta) = \prod_{i \text{ uncensored}} f(y_i | \theta) \times \prod_{j \text { censored}} F(y_j^* | \theta)
\]</span></p>
<p>where <span class="math inline">\(y_j^*\)</span> is the censoring threshold for observation <span class="math inline">\(j\)</span>. If <span class="math inline">\(y_j^* = y^*\)</span> for all censored values (meaning there is only one censoring threshold), then this becomes</p>
<p><span class="math display">\[
L(\theta) = \prod_{i \text{ uncensored}} f(y_i | \theta) \times  [F(y^* | \theta)]^{n_c}
\]</span></p>
<p>where <span class="math inline">\(n_c\)</span> is the number of censored data.</p>
<p>Let’s see an example. I’ll simulate 100 concentration data from a lognormal(0, 1) distribution and censor everything below <span class="math inline">\(exp(-1) = 0.368\)</span>.</p>
<pre class="r"><code>set.seed(23)
ysim = exp(rnorm(100))
centhresh = exp(-1)</code></pre>
<p>Here’s the function for calculating the log likelihood.</p>
<pre class="r"><code>llik = function(mu, sigsq, data, threshold) {
  ldat = log(data)
  cen = data &lt; threshold
#   trm1 = - sum(!cen) / 2 * log(sigsq * 2 * pi)
#   trm2 = - 1 / (2 * sigsq) * sum((ldat[!cen] - mu)^2)
#   trm3 = sum(cen) * log(pnorm((log(threshold) - mu) / sqrt(sigsq)))
#   ll = trm1 + trm2 + trm3
#   ll
  lls1 = dnorm(ldat[!cen], mean = mu, sd = sqrt(sigsq), log = TRUE)
  lls2 = sum(cen) * pnorm(log(threshold), mean = mu, sd = sqrt(sigsq), log.p = TRUE)
  ll = sum(c(lls1, lls2))
  ll
}</code></pre>
<p>Have a look at the resulting log likelihood functions for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span></p>
<pre class="r"><code>mus = seq(-1, 1, length.out = 1000)
sigsqs = seq(0.1, 3, length.out = 1000)

mull = sapply(mus, llik, sigsq = 1, data = ysim, threshold = centhresh)
plot(mus, mull, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>s2ll = sapply(sigsqs, llik, mu = 0, data = ysim, threshold = centhresh)
plot(sigsqs, s2ll, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<pre class="r"><code>(muhat1 = mus[which.max(mull)])</code></pre>
<pre><code>## [1] 0.06306306</code></pre>
<pre class="r"><code>(s2hat1 = sigsqs[which.max(s2ll)])</code></pre>
<pre><code>## [1] 0.907007</code></pre>
<p>Unfortunately, these are not easy to maximize analytically, but as you can see they are both convex (rather, the <em>negative</em> log likelihood is convex) and therefore simple to maximize numerically.</p>
<p>You might be curious as to what the log likelihood functions would look like if I had simply tossed out the sensored data. Let’s find out!</p>
<pre class="r"><code>mull = sapply(mus, llik, sigsq = 1, data = ysim[ysim &gt; centhresh], 
              threshold = centhresh)
plot(mus, mull, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>s2ll = sapply(sigsqs, llik, mu = 0, data = ysim[ysim &gt; centhresh], 
              threshold = centhresh)
plot(sigsqs, s2ll, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
<pre class="r"><code>(muhat2 = mus[which.max(mull)])</code></pre>
<pre><code>## [1] 0.3413413</code></pre>
<pre class="r"><code>(s2hat2 = sigsqs[which.max(s2ll)])</code></pre>
<pre><code>## [1] 0.6428428</code></pre>
<p>The maxima in this case are much farther than the true values I imposed. What about the “half the detection limit” imputation? How would that look?</p>
<pre class="r"><code>ysim2 = ysim
ysim2[ysim &lt; centhresh] = centhresh / 2

mull = sapply(mus, llik, sigsq = 1, data = ysim2, 
              threshold = 0.01)
plot(mus, mull, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>s2ll = sapply(sigsqs, llik, mu = 0, data = ysim2, 
              threshold = 0.01)
plot(sigsqs, s2ll, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<pre class="r"><code>(muhat3 = mus[which.max(mull)])</code></pre>
<pre><code>## [1] 0.03503504</code></pre>
<pre class="r"><code>(s2hat3 = sigsqs[which.max(s2ll)])</code></pre>
<pre><code>## [1] 0.9766767</code></pre>
<p>Hmm. In this case the imputation actually got closer to reality. But I suspect this is a fluke of this dataset. I’m not going to do all the simulations to show this in general, but I think I can come up with a case where my version works better.</p>
<p>Instead of using <span class="math inline">\(\sigma^2 = 1\)</span>, I’ll use something smaller, say 0.04, and a larger threshold, <span class="math inline">\(exp(0) = 1\)</span>.</p>
<pre class="r"><code>set.seed(221)
ysim = exp(rnorm(10000, 0, 0.2))
centhresh = exp(0)</code></pre>
<p>Here’s the log likelihood using the censored MLE method:</p>
<pre class="r"><code>mus = seq(-1, 1, length.out = 1000)
sigsqs = seq(0.01, 0.5, length.out = 1000)

mull = sapply(mus, llik, sigsq = 0.04, data = ysim, threshold = centhresh)
plot(mus, mull, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>s2ll = sapply(sigsqs, llik, mu = 0, data = ysim, threshold = centhresh)
plot(sigsqs, s2ll, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code>(muhat1 = mus[which.max(mull)])</code></pre>
<pre><code>## [1] -0.001001001</code></pre>
<pre class="r"><code>(s2hat1 = sigsqs[which.max(s2ll)])</code></pre>
<pre><code>## [1] 0.04139139</code></pre>
<p>And here’s the imputation method:</p>
<pre class="r"><code>ysim2 = ysim
ysim2[ysim &lt; centhresh] = centhresh / 2

mull = sapply(mus, llik, sigsq = 0.04, data = ysim2, 
              threshold = 0.01)
plot(mus, mull, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>s2ll = sapply(sigsqs, llik, mu = 0, data = ysim2, 
              threshold = 0.01)
plot(sigsqs, s2ll, type = &quot;l&quot;)</code></pre>
<p><img src="/post/2016-01-03-Maximum-Likelihood-Estimation-using-censored-data_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
<pre class="r"><code>(muhat3 = mus[which.max(mull)])</code></pre>
<pre><code>## [1] -0.2712713</code></pre>
<pre class="r"><code>(s2hat3 = sigsqs[which.max(s2ll)])</code></pre>
<pre><code>## [1] 0.2630931</code></pre>
<p>Looking at the estimates side-by-side:</p>
<pre class="r"><code>knitr::kable(data.frame(method = c(&quot;censMLE&quot;, &quot;halfBDL&quot;), 
                        muhat = c(muhat1, muhat3), s2hat = c(s2hat1, s2hat3)))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">muhat</th>
<th align="right">s2hat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">censMLE</td>
<td align="right">-0.0010010</td>
<td align="right">0.0413914</td>
</tr>
<tr class="even">
<td align="left">halfBDL</td>
<td align="right">-0.2712713</td>
<td align="right">0.2630931</td>
</tr>
</tbody>
</table>
<p>So here using 1/2 the detection limit for nondetects <em>really</em> biased the results. Meanwhile, the likelihood method was spot on.</p>
<p>A couple of caveats before signing off. First, this worked so well precisely because the distribution of the data was known. If you don’t know what distribution your data come from, maximum likelihood ceases to be meaningful. Second, note that I didn’t properly maximize the likelihood (with respect to the full parameter space) in the above simulations–that would have required a more sophisticated numerical computation, e.g. gradient descent. Here I used <code>which.max</code> to get the argument that maximized the function for a range of parameter values.</p>
